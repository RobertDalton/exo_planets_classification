
# -------------------- CONTENIDO DE ae_utils.py --------------------
import tensorflow as tf
import pandas as pd
import numpy as np
from typing import Tuple

from keras.models import Model
from keras import layers

# Define la dimensi칩n de entrada
INPUT_DIM = 1000
HE_INIT = 'he_uniform' 
EPSILON = 1e-6 


class AnomalyDetector(Model):
    # 救넖잺 CLAVE 1: Aceptar argumentos gen칠ricos (**kwargs) en el constructor
    # Esto captura 'trainable', 'dtype', etc., que Keras pasa al cargar.
    def __init__(self, **kwargs): 
        super(AnomalyDetector, self).__init__(**kwargs)
        
        # --- ENCODER ---
        self.encoder = tf.keras.Sequential([
            layers.Dense(32, activation="relu", input_shape=(INPUT_DIM,), kernel_initializer=HE_INIT),
            layers.Dense(16, activation="relu", kernel_initializer=HE_INIT),
            layers.Dense(14, activation="relu", kernel_initializer=HE_INIT) 
        ])

        # --- DECODER ---
        self.decoder = tf.keras.Sequential([
            layers.Dense(16, activation="relu", kernel_initializer=HE_INIT),
            layers.Dense(32, activation="relu", kernel_initializer=HE_INIT),
            layers.Dense(INPUT_DIM, activation="linear")
        ])

    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
        
    # 救넖잺 CLAVE 2: Sobrescribir get_config() para la serializaci칩n.
    # Necesitas esto si tu constructor tiene argumentos personalizados,
    # aunque en este caso solo lo defines por buena pr치ctica con **kwargs.
    #def get_config(self):
        # Obtiene la configuraci칩n base de la clase Model
        config = super(AnomalyDetector, self).get_config()
        # Puedes a침adir aqu칤 argumentos espec칤ficos de tu clase si los tuvieras
        # config.update({"my_custom_arg": self.my_custom_arg}) 
        #return config
    
def preprocess_light_curves(df_raw: pd.DataFrame, n_bins: int = 1000) -> pd.DataFrame:
    """
    Normaliza el flujo, aplica binning al tiempo, pivotea el DataFrame para el Autoencoder,
    e imputa NaN con 0.
    
    Args:
        df_raw: DataFrame con columnas ['id', 'time', 'flux'].
        n_bins: N칰mero de bins fijos para la longitud de la serie de tiempo.
        
    Returns:
        DataFrame listo para el entrenamiento del Autoencoder.
    """
    # 1. Normalizaci칩n del Flujo por cada ID
    
    df_normalized = df_raw.copy()
    
    # Normalizaci칩n: (Flujo - Mediana) / Desviaci칩n Est치ndar
    df_normalized['flux_normalized'] = df_normalized.groupby('id')['flux'].transform(
        lambda x: (x - x.median()) / x.std()
    )
    
    # 游 TRATAMIENTO DE NAN 1: Imputar 0 despu칠s de la normalizaci칩n.
    # Esto maneja los casos donde std=0 (l칤nea plana) o datos an칩malos.
    df_normalized['flux_normalized'] = df_normalized['flux_normalized'].fillna(0)
    
    # 2. Binning del Tiempo (Crear el 칤ndice de columna fija)

    def calculate_bins(series: pd.Series, max_bins: int) -> pd.Series:
        """Calcula el 칤ndice del bin [0, max_bins-1] para cada punto de tiempo."""
        time_min = series.min()
        time_max = series.max()
        time_range = time_max - time_min
        
        if time_range == 0 or pd.isna(time_range):
            return pd.Series(0, index=series.index)
        
        # Mapea el tiempo relativo [0, 1] al 칤ndice del bin [0, N_BINS-1]
        bin_index = ((series - time_min) / time_range) * (max_bins - 1)
        return np.floor(bin_index).astype(int)

    # Aplica la funci칩n de binning para obtener la columna 'bin_index'
    df_normalized['bin_index'] = df_normalized.groupby('id')['time'].transform(
        lambda x: calculate_bins(x, n_bins)
    )
    
    # 3. Agregaci칩n (Remuestreo) y Pivot
    
    # Agrupar por ID y BIN_INDEX y tomar la media del flujo normalizado
    df_binned = df_normalized.groupby(['id', 'bin_index'])['flux_normalized'].mean().reset_index()
    
    # Pivotear la tabla: 'id' como 칤ndice, 'bin_index' como columnas
    df_final = df_binned.pivot(index='id', columns='bin_index', values='flux_normalized')
    
    # 游 TRATAMIENTO DE NAN 2: Rellenar los NaNs restantes.
    # Estos NaNs se generan porque algunos bins no ten칤an ninguna observaci칩n.
    df_final = df_final.fillna(0)

    expected_bins = range(n_bins)

    # Renombrar las columnas para tener nombres limpios (ej. 'flux_0', 'flux_1'...)
    #df_final.columns = [f'flux_{i}' for i in range(n_bins)]

    # Aplica la reindexaci칩n al eje de columnas (axis=1)
    # Esto asegura que el DataFrame tenga EXACTAMENTE 1000 columnas (0 a 999)
    df_final = df_final.reindex(columns=expected_bins, fill_value=0)

    # 救넖잺 AHORA, la asignaci칩n de nombres es segura:
    df_final.columns = [f'flux_{i}' for i in range(n_bins)]

    
    # Resetear el 칤ndice si quieres 'id' como una columna normal
    df_final = df_final.reset_index()

    return df_final